{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\HP\\\\Desktop\\\\E-Vision-Projects\\\\Product_Count_API\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\E-Vision-Projects\\Product_Count_API\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\HP\\\\Desktop\\\\E-Vision-Projects\\\\Product_Count_API'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "%cd ..\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import cv2\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChromaDB client\n",
    "chroma_client = chromadb.PersistentClient(path=\"./data/chroma_product_db\")  # Persistent storage\n",
    "\n",
    "# Create a collection for storing product embeddings\n",
    "# collection = chroma_client.get_or_create_collection(name=\"product_embeddings\")\n",
    "\n",
    "collection =chroma_client.get_or_create_collection(\n",
    "    name=\"collection_name\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"} # l2 is the default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\E-Vision-Projects\\Product_Count_API\\proobj\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\Desktop\\E-Vision-Projects\\Product_Count_API\\proobj\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet50 for feature extraction\n",
    "class FeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        self.feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])  # Remove classification layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        return x.view(x.size(0), -1)  # Flatten output\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "feature_extractor = FeatureExtractor().to(device).eval()\n",
    "\n",
    "# Image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def extract_cnn_features(image):\n",
    "    \"\"\"Extracts feature embeddings using ResNet50.\"\"\"\n",
    "    image = Image.open(image).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Transform & Add batch dim\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = feature_extractor(image).cpu().numpy().flatten()\n",
    "\n",
    "    return features  # Return feature embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_embedding_chromadb(product_name, embedding):\n",
    "    \"\"\"Stores multiple embeddings for the same product in ChromaDB.\"\"\"\n",
    "    collection.add(\n",
    "        ids=[f\"{product_name}_{np.random.randint(100000)}\"],  # Unique ID for each image\n",
    "        embeddings=[embedding.tolist()],  # Convert to list for ChromaDB\n",
    "        metadatas=[{\"product_name\": product_name}]  # Store metadata\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_best_match_chromadb(query_embedding, threshold=0.5):\n",
    "    \"\"\"Finds the best matching product using ChromaDB similarity search.\"\"\"\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding.tolist()], \n",
    "        n_results=1  # Get the best match\n",
    "    )\n",
    "    \n",
    "    # print(results[\"distances\"][0][0])\n",
    "    # # Check if the best match is above the threshold\n",
    "    # if results[\"distances\"][0][0] > threshold:\n",
    "    #     return \"New Product\"\n",
    "\n",
    "    # return results[\"metadatas\"][0][0][\"product_name\"]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_lis = glob.glob(os.path.join('./data/db/','*/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dict ={'1000':'7-oil-red', '1001':'7-oil-green', '1002':'7-oil-black', '1003':'7-oil-brown', '1004':'7-oil-yellow', \n",
    "          '1005':'7-oil-orange', '1006':'fathima-kesha-wardhani', '1007':'nawarathna-oil-box-green',\n",
    "          '1008':'nawarathna-oil-box-red', '1009':'janet-hair-fall-red', '1010':'janet-hair-fall-blue',\n",
    "          '1011':'bread-growth', '1012':'7-oil-white', '1013':'castor-oil', '1014':'hair-care-oil-blue', '1015':'jasmin-coconut-hari-oil',\n",
    "          '1016':'chandanalepa-box', '1017':'pears-baby-cream','1018':'parachuti-hail-oil',\n",
    "          '1019':'amla-hurbal-hail-oil'\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image in enumerate(image_lis):\n",
    "    encodding = extract_cnn_features(image)\n",
    "    image_name = db_dict[image.split('\\\\')[-2]]\n",
    "    store_embedding_chromadb(image_name, encodding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def delete_product_by_name(product_name):\n",
    "#     \"\"\"Deletes all embeddings for a given product name.\"\"\"\n",
    "#     results = collection.get(where={\"product_name\": product_name})  # Retrieve all matching entries\n",
    "#     ids_to_delete = results[\"ids\"]\n",
    "\n",
    "#     if ids_to_delete:\n",
    "#         collection.delete(ids=ids_to_delete)\n",
    "#         print(f\"Deleted all embeddings for '{product_name}'.\")\n",
    "#     else:\n",
    "#         print(f\"No embeddings found for '{product_name}'.\")\n",
    "\n",
    "# # Example Usage\n",
    "# delete_product_by_name(\"Coca Cola 500ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Match: {'ids': [['7-oil-red_9348']], 'embeddings': None, 'documents': [[None]], 'uris': None, 'data': None, 'metadatas': [[{'product_name': '7-oil-red'}]], 'distances': [[0.06010927039596747]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "query_img = './data/test_output/cropped_image_5.jpg'\n",
    "# Example: Match a new product image\n",
    "query_embedding = extract_cnn_features(query_img)\n",
    "matched_product = retrieve_best_match_chromadb(query_embedding)\n",
    "print(\"Best Match:\", matched_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7-oil-red'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_product[\"metadatas\"][0][0][\"product_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img_lis = glob.glob(os.path.join('./data/test_output/','*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1: castor-oil distance: 0.15015782217421958\n",
      "Image 2: 7-oil-black distance: 0.058799279841256435\n",
      "Image 3: 7-oil-red distance: 0.011855254166439955\n",
      "Image 4: 7-oil-orange distance: 0.07780938422863726\n",
      "Image 5: 7-oil-yellow distance: 0.1911783526504831\n",
      "Image 6: 7-oil-white distance: 0.1256673079559908\n",
      "Image 7: jasmin-coconut-hari-oil distance: 0.09266074760966059\n",
      "Image 8: 7-oil-orange distance: 0.017132066986998873\n",
      "Image 9: amla-hurbal-hail-oil distance: 0.18190745926944385\n",
      "Image 10: 7-oil-red distance: 0.06292963711472566\n",
      "Image 11: 7-oil-black distance: 0.040860480607634586\n",
      "Image 12: 7-oil-black distance: 0.062265289360884934\n",
      "Image 13: 7-oil-yellow distance: 0.10759544869670212\n",
      "Image 14: 7-oil-red distance: 0.06010927039596747\n",
      "Image 15: janet-hair-fall-red distance: 0.14080361519810347\n",
      "Image 16: 7-oil-black distance: 0.06671115551480289\n",
      "Image 17: 7-oil-yellow distance: 0.07611340348244666\n",
      "Image 18: jasmin-coconut-hari-oil distance: 0.14856678033864423\n"
     ]
    }
   ],
   "source": [
    "for i, img in enumerate(query_img_lis):\n",
    "    encodding = extract_cnn_features(img)\n",
    "    matched_product = retrieve_best_match_chromadb(encodding)\n",
    "    print(f\"Image {i+1}: {matched_product['metadatas'][0][0]['product_name']} distance: {matched_product['distances'][0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proobj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
